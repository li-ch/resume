<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Li Chen</title>
    <link>https://li-ch.github.io/resume/project/</link>
    <description>Recent content in Projects on Li Chen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Thu, 24 Aug 2017 19:34:48 +0800</lastBuildDate><atom:link href="https://li-ch.github.io/resume/project/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RDMA over Converged Ethernet (RoCE) For Large-scale Deep Learning with Amber</title>
      <link>https://li-ch.github.io/resume/project/amber/</link>
      <pubDate>Thu, 24 Aug 2017 19:34:48 +0800</pubDate>
      
      <guid>https://li-ch.github.io/resume/project/amber/</guid>
      <description>With the rapid growth of model complexity and data volume, deep learning systems require more and more servers to perform parallel training. Currently, deep learning systems with multiple servers and multiple GPUs are usually implemented in a single cluster, which typically employs Infiniband fabric to support Remote Direct Memory Access (RDMA), so as to achieve high throughput and low latency for inter-server transmission. It is expected that, with ever-larger models and data, deep learning systems must scale to multiple network clusters, which necessitates highly efficient inter-cluster networking stack with RDMA support. Since Infiniband is only suited for small-scale clusters of less than thousands of servers, we believe RDMA-over-Converged-Ethernet (RoCE) is a more appropriate networking technology choice for multi-cluster datacenter-scale deep learning. Therefore, we endeavor to incorporate RoCE as the networking technology for deep learning systems, such as Tensorflow and Tencent&amp;rsquo;s Amber.</description>
    </item>
    
    <item>
      <title>Angel: Network-Accelerated Large-Scale Machine Learning</title>
      <link>https://li-ch.github.io/resume/project/angel/</link>
      <pubDate>Wed, 26 Oct 2016 19:34:48 +0800</pubDate>
      
      <guid>https://li-ch.github.io/resume/project/angel/</guid>
      <description>Angel is an in-house large scale machine learning framework in Tencent. We cooperated with Technology Engineering Group (TEG), and developed a network accelerator. Via algorithm-specific flow scheduling, We achieved 70x reduction in job completion time compared to vanilla Apache Spark.</description>
    </item>
    
    <item>
      <title>Chukonu: Application-Aware Networking</title>
      <link>https://li-ch.github.io/resume/project/app-aware/</link>
      <pubDate>Wed, 26 Oct 2016 17:18:51 +0800</pubDate>
      
      <guid>https://li-ch.github.io/resume/project/app-aware/</guid>
      <description>Datacenters exists because of a standalone server/rack can no longer meet the requirements of modern day applications: web search, ad recommendation, online commerce, machine learning, etc. Different from traditional networks, data center networks enjoy high bandwidth, low latency, and minimal packet loss. These features, however, are not fully utilized today, because application developers are usually unfamiliar with datacenter environment and/or networking stack and its tuning. We aim to design a system for application developers to access networking functions in datacenters and unlock its full potential.</description>
    </item>
    
  </channel>
</rss>
